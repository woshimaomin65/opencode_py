# OpenCode Python LLM é…ç½®æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨ç»Ÿä¸€çš„ LLM é…ç½®ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§ AI æä¾›è€…ï¼š
- Anthropic (Claude)
- OpenAI (GPT)
- Google (Gemini)
- Azure OpenAI
- Ollama (æœ¬åœ°æ¨¡å‹)
- LM Studio (æœ¬åœ°æ¨¡å‹)

## ğŸ”§ é…ç½®æ–‡ä»¶

### 1. æœ¬åœ°é…ç½®æ–‡ä»¶ï¼ˆä¸ä¸Šä¼ åˆ° Gitï¼‰

åˆ›å»º `local_llm_config.json` æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š

```json
{
  "default_provider": "anthropic",
  "default_model": "claude-sonnet-4-20250514",
  "providers": {
    "anthropic": {
      "name": "anthropic",
      "base_url": "https://api.anthropic.com",
      "api_key_env": "ANTHROPIC_API_KEY",
      "default_model": "claude-sonnet-4-20250514",
      "timeout": 600,
      "max_retries": 3
    },
    "openai": {
      "name": "openai",
      "base_url": "https://api.openai.com/v1",
      "api_key_env": "OPENAI_API_KEY",
      "default_model": "gpt-4o",
      "timeout": 600,
      "max_retries": 3
    }
  }
}
```

**æ³¨æ„**: æ­¤æ–‡ä»¶å·²æ·»åŠ åˆ° `.gitignore`ï¼Œä¸ä¼šè¢«ä¸Šä¼ åˆ° Gitã€‚

### 2. ç¯å¢ƒå˜é‡

ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
# Anthropic
export ANTHROPIC_API_KEY=your_api_key_here

# OpenAI
export OPENAI_API_KEY=your_api_key_here

# Google
export GOOGLE_API_KEY=your_api_key_here

# Azure
export AZURE_OPENAI_API_KEY=your_api_key_here

# è‡ªå®šä¹‰ Base URL
export ANTHROPIC_BASE_URL=https://api.anthropic.com
export OPENAI_BASE_URL=https://api.openai.com/v1
```

### 3. ç›´æ¥ä»£ç é…ç½®

```python
from llm_config import LLMConfigManager

config = LLMConfigManager()
config.load()

# è·å–æä¾›è€…é…ç½®
anthropic_config = config.get_provider("anthropic")
api_key = config.get_api_key("anthropic")
base_url = config.get_base_url("anthropic")
model = config.get_model("anthropic")

# è·å–é»˜è®¤å€¼
default_provider = config.get_default_provider()
default_model = config.get_default_model()
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### ä½¿ç”¨ Provider æ¨¡å—

```python
from provider import get_provider, get_default_provider

# ä½¿ç”¨é»˜è®¤æä¾›è€…ï¼ˆä»é…ç½®è¯»å–ï¼‰
provider = get_default_provider()

# ä½¿ç”¨ç‰¹å®šæä¾›è€…
anthropic = get_provider("anthropic")
openai = get_provider("openai")

# è‡ªå®šä¹‰é…ç½®
custom_provider = get_provider(
    provider_type="anthropic",
    model="claude-opus-4-20250514",
    api_key="your_custom_key",  # å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®
)
```

### ä½¿ç”¨ Config æ¨¡å—

```python
from config import Config

config = Config()
config.load()

# è·å– LLM é…ç½®
llm_config = config.llm_config

# è·å– API å¯†é’¥
api_key = config.get_llm_api_key("anthropic")

# è·å–é»˜è®¤æä¾›è€…
default_provider = config.get_default_llm_provider()
default_model = config.get_default_llm_model()
```

### åœ¨ Agent ä¸­ä½¿ç”¨

```python
from agent import Agent
from config import Config

# åŠ è½½é…ç½®
config = Config()
config.load()

# åˆ›å»º Agentï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨é…ç½®çš„æä¾›è€…ï¼‰
agent = Agent(
    project_root="/path/to/project",
    config=config,
)

# è¿è¡Œ Agent
result = await agent.run("è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªä»£ç åº“")
```

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¸è¦ç¡¬ç¼–ç  API å¯†é’¥**: ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–æœ¬åœ°é…ç½®æ–‡ä»¶
2. **æœ¬åœ°é…ç½®æ–‡ä»¶ä¸ä¸Šä¼ **: `local_llm_config.json` å·²åœ¨ `.gitignore` ä¸­
3. **ä½¿ç”¨ .env æ–‡ä»¶**: å¯ä»¥åˆ›å»º `.env.local` å­˜å‚¨æ•æ„Ÿä¿¡æ¯
4. **å®šæœŸè½®æ¢å¯†é’¥**: å®šæœŸæ›´æ–° API å¯†é’¥

## ğŸ“ é…ç½®ä¼˜å…ˆçº§

é…ç½®åŠ è½½ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š

1. **æ˜¾å¼å‚æ•°**: ä»£ç ä¸­ç›´æ¥ä¼ å…¥çš„å‚æ•°
2. **æœ¬åœ°é…ç½®æ–‡ä»¶**: `local_llm_config.json`
3. **ç¯å¢ƒå˜é‡**: å¦‚ `ANTHROPIC_API_KEY`
4. **é»˜è®¤è®¾ç½®**: å†…ç½®çš„é»˜è®¤é…ç½®

## ğŸŒ æä¾›è€…é…ç½®è¯´æ˜

### Anthropic

```json
{
  "anthropic": {
    "name": "anthropic",
    "base_url": "https://api.anthropic.com",
    "api_key_env": "ANTHROPIC_API_KEY",
    "default_model": "claude-sonnet-4-20250514",
    "timeout": 600,
    "max_retries": 3
  }
}
```

### OpenAI

```json
{
  "openai": {
    "name": "openai",
    "base_url": "https://api.openai.com/v1",
    "api_key_env": "OPENAI_API_KEY",
    "default_model": "gpt-4o",
    "timeout": 600,
    "max_retries": 3
  }
}
```

### Google

```json
{
  "google": {
    "name": "google",
    "base_url": null,
    "api_key_env": "GOOGLE_API_KEY",
    "default_model": "gemini-2.0-flash",
    "timeout": 600,
    "max_retries": 3
  }
}
```

### Ollama (æœ¬åœ°)

```json
{
  "ollama": {
    "name": "ollama",
    "base_url": "http://localhost:11434/v1",
    "api_key_env": null,
    "default_model": "llama3.1",
    "timeout": 600,
    "max_retries": 3
  }
}
```

### LM Studio (æœ¬åœ°)

```json
{
  "lmstudio": {
    "name": "lmstudio",
    "base_url": "http://localhost:1234/v1",
    "api_key_env": null,
    "default_model": "local-model",
    "timeout": 600,
    "max_retries": 3
  }
}
```

## ğŸ” è°ƒè¯•

### æŸ¥çœ‹å½“å‰é…ç½®

```python
from llm_config import get_llm_config

config = get_llm_config()
print(config.to_dict())
```

### é‡æ–°åŠ è½½é…ç½®

```python
from llm_config import reload_llm_config

config = reload_llm_config()  # é‡æ–°åŠ è½½æœ¬åœ°é…ç½®æ–‡ä»¶
```

### æ£€æŸ¥ API å¯†é’¥

```python
from llm_config import get_api_key

key = get_api_key("anthropic")
if key:
    print("API key is configured")
else:
    print("API key is missing!")
```

## ğŸ“š ç›¸å…³æ–‡ä»¶

- `llm_config.py` - LLM é…ç½®ç®¡ç†æ ¸å¿ƒæ¨¡å—
- `local_llm_config.json` - æœ¬åœ°é…ç½®æ–‡ä»¶ï¼ˆä¸ä¸Šä¼ ï¼‰
- `config/config.py` - é€šç”¨é…ç½®æ¨¡å—ï¼ˆé›†æˆ LLM é…ç½®ï¼‰
- `provider/provider.py` - æä¾›è€…æ¨¡å—ï¼ˆä½¿ç”¨ LLM é…ç½®ï¼‰
- `.gitignore` - Git å¿½ç•¥è§„åˆ™ï¼ˆåŒ…å«æœ¬åœ°é…ç½®ï¼‰

## ğŸ†˜ æ•…éšœæ’é™¤

### é—®é¢˜ï¼šAPI å¯†é’¥æœªæ‰¾åˆ°

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦è®¾ç½®ï¼š`echo $ANTHROPIC_API_KEY`
2. æ£€æŸ¥ `local_llm_config.json` æ˜¯å¦å­˜åœ¨
3. æ£€æŸ¥ `api_key_env` å­—æ®µæ˜¯å¦æ­£ç¡®

### é—®é¢˜ï¼šé…ç½®æœªç”Ÿæ•ˆ

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿è°ƒç”¨ `config.load()` åŠ è½½é…ç½®
2. æ£€æŸ¥é…ç½®æ–‡ä»¶ JSON æ ¼å¼æ˜¯å¦æ­£ç¡®
3. æŸ¥çœ‹æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯

### é—®é¢˜ï¼šæ¨¡å‹åç§°é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ `default_model` é…ç½®æ˜¯å¦æ­£ç¡®
2. ç¡®è®¤æä¾›è€…æ”¯æŒè¯¥æ¨¡å‹
3. æŸ¥çœ‹æä¾›è€…æ–‡æ¡£ç¡®è®¤æ¨¡å‹åç§°

---

*æœ€åæ›´æ–°ï¼š2024*
